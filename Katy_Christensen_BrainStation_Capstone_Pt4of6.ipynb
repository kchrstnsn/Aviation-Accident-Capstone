{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b25d04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc330c5",
   "metadata": {},
   "source": [
    "# Aviation Accident Capstone:\n",
    "## *Part IV: Decision Tree Model*\n",
    "Created by: Katy Christensen <br>\n",
    "Created on: September 26, 2022 <br>\n",
    "Created for: BrainStation Data Science Bootcamp Capstone<br>\n",
    "Notebook 4 of 6<br>\n",
    "\n",
    "Previous Notebook: *Part III: Logistic Regression Model* <br>\n",
    "Upcoming Notebook: *Part V: K-Nearest Neighbor Model* <br>\n",
    "\n",
    "--------------\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6810568",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "[1. Load Data & Review](#Step-1) <br>\n",
    "[2. Splitting Data](#Step-2) <br>\n",
    "- [Train-Test Split](#test-split) <br>\n",
    "- [Train-Validation Split](#val-split)<br>\n",
    "\n",
    "[3. Modeling](#Step-3) <br>\n",
    "- [Baseline Decision Tree](#base-dt) <br>\n",
    "\n",
    "[4. Hyperparameter Optimization](#Step-4) <br>\n",
    "- [Max_Depth](#max_depth) <br>\n",
    "- [Min_Samples_Leaf](#min-leaf) <br>\n",
    "- [Refit Decision Tree](#refit)<br>\n",
    "\n",
    "[5. Model Evaluation](#Step-5) <br>\n",
    "[6. Results & Summary](#Step-6) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78137718",
   "metadata": {},
   "source": [
    "--------\n",
    "<a id='Step-1'></a>\n",
    "### 1. Load Data & Review\n",
    "--------\n",
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06bb9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntsb08 = pd.read_csv('data/ntsb08_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2514f3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ntsb08.drop(columns='ev_highest_injury')\n",
    "y = ntsb08['ev_highest_injury']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bb7329",
   "metadata": {},
   "source": [
    "--------\n",
    "<a id='Step-2'></a>\n",
    "### 2. Splitting the Data\n",
    "---------\n",
    "<a id='test-split'></a>\n",
    "#### Train-Test Split\n",
    "The first split is the train/test split; 70% of the data is allocated to the training data and 30% to the final test data. The data is stratified to ensure similar distributions to the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd5091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the test into train (70%) and test (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=5, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb801c1",
   "metadata": {},
   "source": [
    "<a id='val-split'></a>\n",
    "#### Train-Validation Split\n",
    "The second split is the train/validation split; 80% of the data is allocated to the training data and 20% to the validation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd169bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the test into train (80%) and test (20%)\n",
    "X_train2, X_val, y_train2, y_val = train_test_split(X_train, y_train, test_size=0.2, \n",
    "                                                    random_state=6, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e392a13",
   "metadata": {},
   "source": [
    "--------------\n",
    "<a id='Step-3'></a>\n",
    "### 3. Modeling\n",
    "--------------\n",
    "<a id='base-dt'></a>\n",
    "#### Baseline Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33afe627",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "# Instantiate\n",
    "ntsb_dt = DecisionTreeClassifier()\n",
    "\n",
    "# Fit\n",
    "ntsb_dt.fit(X_train2, y_train2)\n",
    "\n",
    "# Score\n",
    "print(f'Train Accuracy Score: {ntsb_dt.score(X_train2, y_train2)}')\n",
    "print(f'Test Accuracy Score: {ntsb_dt.score(X_val, y_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83df7437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate & fit PCA model to data\n",
    "# Default n_components will generate the same number of PCs as you have features \n",
    "dt_PCA = PCA(n_components=10)\n",
    "dt_PCA.fit(X_train2)\n",
    "\n",
    "# transform data \n",
    "dt_train_PCA = dt_PCA.transform(X_train2)\n",
    "dt_val_PCA = dt_PCA.transform(X_val)\n",
    "\n",
    "# Instantiate\n",
    "dt_PCA = DecisionTreeClassifier()\n",
    "\n",
    "# Fit\n",
    "dt_PCA.fit(X_train2, y_train2)\n",
    "\n",
    "# Score \n",
    "print(f\"Train Set Accuracy: {dt_PCA.score(X_train2, y_train2)}\")\n",
    "print(f\"Test Set Accuracy: {dt_PCA.score(X_val, y_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae71c44",
   "metadata": {},
   "source": [
    "------------\n",
    "<a id='Step-4'></a>\n",
    "### 4. Hyperparameter Optimization\n",
    "------------\n",
    "Hyperparameter optimization is important because Decision Tree models will overfit since they continue to split through every feature. Pre-pruning is an effort to curb this tendency by setting hyperparameter limits on:\n",
    "1. `max_depth`: limits the consecutive splits the model can make, resulting in a \"simplified tree\" that limit how well the model can fit branches to a single data point.\n",
    "2. `min_samples_leaf`: forces the model to fit around larger data regions, which prevents fitting around individual data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11c563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_depth = range(1, 11, 1)\n",
    "# FIT DECISION TREE\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "for depth in m_depth:\n",
    "\n",
    "    # 1. Instantiate \n",
    "    ntsb_tree = DecisionTreeClassifier(max_depth=depth)\n",
    "\n",
    "    # 2. Fit (on the train set)\n",
    "    ntsb_tree.fit(X_train, y_train)\n",
    "\n",
    "    # 3. Score (on both sets)\n",
    "    train_score = ntsb_tree.score(X_train2, y_train2)\n",
    "    test_score = ntsb_tree.score(X_val, y_val)\n",
    "    \n",
    "    # Add these to the lists\n",
    "    train_accs.append(train_score)\n",
    "    test_accs.append(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451d5de8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize\n",
    "plt.figure()\n",
    "plt.plot(range(1, 21), train_accs, label='train', marker='o')\n",
    "plt.plot(range(1, 21), test_accs, label='test', marker='o')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce2842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#index value that is the largest in the test accuracy\n",
    "index_of_max = np.argmax(test_accs)\n",
    "\n",
    "#the corresponding coordinate k value\n",
    "best_md = m_depth[index_of_max]\n",
    "print(f'Best max depth value: {best_md}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdfd345",
   "metadata": {},
   "source": [
    "**Comment:** The best max depth is at easier 4 or 6. This can be determined by using a pipeline to test for specific pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67f8dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_leaf = range(1, 21, 1) \n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "for leaves in min_leaf:\n",
    "\n",
    "    # 1. Instantiate \n",
    "    ntsb_tree = DecisionTreeClassifier(min_samples_leaf=leaves)\n",
    "\n",
    "    # 2. Fit (on the train set)\n",
    "    ntsb_tree.fit(X_train, y_train)\n",
    "\n",
    "    # 3. Score (on both sets)\n",
    "    train_score = ntsb_tree.score(X_train2, y_train2)\n",
    "    test_score = ntsb_tree.score(X_val, y_val)\n",
    "    \n",
    "    # Add these to the lists\n",
    "    train_accs.append(train_score)\n",
    "    test_accs.append(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68ae808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#index value that is the largest in the test accuracy\n",
    "index_of_max = np.argmax(test_accs)\n",
    "\n",
    "#the corresponding coordinate k value\n",
    "best_ms = min_leaf[index_of_max]\n",
    "print(f'Best max depth value: {best_ms}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d9a14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we give our estimators as a list of tuples: name:function.\n",
    "estimator = [('model', DecisionTreeClassifier())]\n",
    "\n",
    "pipe = Pipeline(estimator)\n",
    "\n",
    "param_grid = [\n",
    "        {'model': [DecisionTreeClassifier()], \n",
    "         'model__max_depth': [7, 9, 13, 21],\n",
    "         'model__min_samples_leaf': [1, 2, 3],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "fittedgrid = grid.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a3c0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fittedgrid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddea50b",
   "metadata": {},
   "source": [
    "<a id='refit'></a>\n",
    "#### Refitting Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07af579e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "# Instantiate\n",
    "ntsb_dt6 = DecisionTreeClassifier(max_depth=6, min_samples_leaf=2 )\n",
    "\n",
    "# Fit\n",
    "ntsb_dt6.fit(X_train2, y_train2)\n",
    "\n",
    "# Score\n",
    "print(f'Train Score: {ntsb_dt6.score(X_train2, y_train2)}')\n",
    "print(f'Validation Score: {ntsb_dt6.score(X_val, y_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffe6d66",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='Results'></a>\n",
    "## 6. Results & Summary \n",
    "---\n",
    "dfs\n",
    "\n",
    "---\n",
    "#### <div align = \"right\">Up Next:</div>\n",
    "<div align = \"right\">Aviation Accident Captson Part V: K-Nearest Neighbor</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
