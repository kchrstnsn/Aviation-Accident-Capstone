{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0137a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Ignore futurewarnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6203344",
   "metadata": {},
   "source": [
    "# Aviation Accident Capstone:\n",
    "## *Part VI: Model Selection & Evaluation*\n",
    "Created by: Katy Christensen <br>\n",
    "Created on: September 26, 2022 <br>\n",
    "Created for: BrainStation Data Science Bootcamp Capstone<br>\n",
    "Notebook 6 of 6<br>\n",
    "\n",
    "Previous Notebook: *Part V: Decision Tree Model* <br>\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49809235",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "[1. Load Data](#Step-1) <br>\n",
    "[2. Split Data](#Step-2) <br>\n",
    "- [Train-Test Split](#Step-2) <br>\n",
    "- [Train-Validation Split](#train-val)\n",
    "\n",
    "[3. Model Selection](#Step-3) <br>\n",
    "- [Fit Baseline Models](#Step-3)<br>\n",
    "- [Optimize Models](#optimize)<br>\n",
    "- [Select Model](#select)<br>\n",
    "- [Fit Final Model](#fit-final)<br>\n",
    "\n",
    "[4. Model Evaluation](#Step-4) <br>\n",
    "- [Confusion Matrix](#Step-4)<br>\n",
    "- [AUC/ROC Evaluation](#auc-roc)<br>\n",
    "\n",
    "[5. Class Balance](#Step-5) <br>\n",
    "- [Up Sampling](#Step-5)<br>\n",
    "- [Down Sampling](#down-samp)<br>\n",
    "\n",
    "[6. Results & Summary](#Step-6) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d8c8c6",
   "metadata": {},
   "source": [
    "--------\n",
    "<a id='Step-1'></a>\n",
    "## 1. Load Data\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd9e9f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntsb08 = pd.read_csv('data/ntsb08_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01528c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ntsb08.drop(columns='ev_highest_injury')\n",
    "y = ntsb08['ev_highest_injury']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a302a733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64192, 10453)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6460f3e2",
   "metadata": {},
   "source": [
    "--------\n",
    "<a id='Step-2'></a>\n",
    "## 2. Split Data\n",
    "--------\n",
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "493b8d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the test into train (70%) and test (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=9, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c091504f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (44934, 10453)\n",
      "X_test shape: (19258, 10453)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6de099b",
   "metadata": {},
   "source": [
    "<a id='train-val'></a>\n",
    "### Train-Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e12e1d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the test into train (80%) and test (20%)\n",
    "X_train2, X_val, y_train2, y_val = train_test_split(X_train, y_train, test_size=0.2, \n",
    "                                                    random_state=18, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49f724e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train2 shape: (35947, 10453)\n",
      "X_val shape: (8987, 10453)\n"
     ]
    }
   ],
   "source": [
    "print('X_train2 shape:', X_train2.shape)\n",
    "print('X_val shape:', X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452d32ea",
   "metadata": {},
   "source": [
    "### Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a961787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale Data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train2)\n",
    "X_scale = scaler.transform(X_train2)\n",
    "X_scale_t = scaler.transform(X_train)\n",
    "X_sval = scaler.transform(X_val)\n",
    "X_stest = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c4c14b",
   "metadata": {},
   "source": [
    "--------\n",
    "<a id='Step-3'></a>\n",
    "## 3. Model Selection\n",
    "--------\n",
    "### Fit Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344d4c3b",
   "metadata": {},
   "source": [
    "##### (A) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6c1492c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Accuracy: 0.8116393579436393\n",
      "Test Set Accuracy: 0.8118393234672304\n"
     ]
    }
   ],
   "source": [
    "# Fitting the logistic model\n",
    "log_base = LogisticRegression(random_state=9)\n",
    "log_base.fit(X_train2, y_train2)\n",
    "\n",
    "# Evaluate its classification accuracy (Just on the training set for now)\n",
    "print(f\"Train Set Accuracy: {log_base.score(X_train2, y_train2)}\")\n",
    "print(f\"Test Set Accuracy: {log_base.score(X_val, y_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebc6517",
   "metadata": {},
   "source": [
    "##### (B) Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d06cc40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Accuracy: 1.0\n",
      "Test Set Accuracy: 0.9448091687993769\n"
     ]
    }
   ],
   "source": [
    "# Instantiate\n",
    "dt_base = DecisionTreeClassifier(random_state=2)\n",
    "\n",
    "# Fit\n",
    "dt_base.fit(X_train2, y_train2)\n",
    "\n",
    "# Score\n",
    "print(f'Train Set Accuracy: {dt_base.score(X_train2, y_train2)}')\n",
    "print(f'Test Set Accuracy: {dt_base.score(X_val, y_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bc6f2b",
   "metadata": {},
   "source": [
    "##### (C) KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfbfed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neighbors: 5\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model & fit it to our data\n",
    "KNN_base = KNeighborsClassifier()\n",
    "KNN_base.fit(X_train2, y_train2)\n",
    "\n",
    "# Score the model on the test set\n",
    "print(\"Number of neighbors:\", KNN_base.n_neighbors)\n",
    "print(\"Train accuracy:\", KNN_base.score(X_train2, y_train2))\n",
    "print(\"Test accuracy:\", KNN_base.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f34313",
   "metadata": {},
   "source": [
    "<a id='optimize'></a>\n",
    "### Optimize Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c05e752",
   "metadata": {},
   "source": [
    "##### KNN Model:\n",
    "KNN models are computationally expensive and to reduce the estimator time, the n_neighbors hyperparameter was optimized before running a machine learning (ML) pipeline for model selection. The pipeline is designed to optimize hyperparameters and will also output the best model for the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf20458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neighbors = range(1, 21, 2) \n",
    "# range is a list iterator\n",
    "# X_train.shape[0] = working in the first dimension of my array\n",
    "#2 = step size so only odd numbers show up\n",
    "\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "for n in neighbors: \n",
    "    print(f\"Working on my model with {n} neighbors...\", end=\"\\r\")\n",
    "    \n",
    "    #Instantiate and Fit\n",
    "    KNN_model = KNeighborsClassifier(n_neighbors=n)\n",
    "    KNN_model.fit(X_scale, y_train2)\n",
    "    \n",
    "    \n",
    "    #Score the model\n",
    "    train_accuracy = KNN_model.score(X_scale, y_train2)\n",
    "    test_accuracy = KNN_model.score(X_val, y_val)\n",
    "    \n",
    "    \n",
    "    #Append my accuracy\n",
    "    train_acc.append(train_accuracy)\n",
    "    test_acc.append(test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1f5be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#index value that is the largest in the test accuracy\n",
    "index_of_max = np.argmax(test_acc)\n",
    "\n",
    "#the corresponding coordinate k value\n",
    "best_k = neighbors[index_of_max]\n",
    "print(f'Best KNN k value: {best_k}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00d5442",
   "metadata": {},
   "source": [
    "<a id='select'></a>\n",
    "### Model Tuning: \n",
    "##### (A) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ada876",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('dim_reducer', PCA()),\n",
    "    ('model', LogisticRegression())\n",
    "]\n",
    "\n",
    "model_pipe = Pipeline(estimators)\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'scaler': [StandardScaler(), None],\n",
    "        'dim_reducer': [PCA()],\n",
    "        'model': [LogisticRegression()], \n",
    "        'model__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'model__penalty': ['l1', 'l2'],\n",
    "        'dim_reducer__n_components': [0, 2, 3, 4, 5, 6]\n",
    "    }\n",
    "]\n",
    "grid = GridSearchCV(model_pipe, param_grid, cv=5)\n",
    "logreg_search = grid.fit(X_train2, y_train2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40e3694",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f954dd73",
   "metadata": {},
   "source": [
    "##### (B) Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1357b2f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create placeholders for the three steps of scaling, dimention reduction, and model\n",
    "estimators = [\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('dim_reducer', PCA()),\n",
    "    ('model', LogisticRegression())\n",
    "]\n",
    "\n",
    "model_pipe = Pipeline(estimators)\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'scaler': [StandardScaler(), None],\n",
    "        'dim_reducer':[PCA()],\n",
    "        'model': [DecisionTreeClassifier()], \n",
    "        'model__max_depth': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "        'model__min_samples_leaf': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'dim_reducer__n_components': [0, 2, 3, 4, 5, 6]\n",
    "    }\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(model_pipe, param_grid, cv=5)\n",
    "dt_search = grid.fit(X_train2, y_train2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff41db49",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e10ba02",
   "metadata": {},
   "source": [
    "##### (C) KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa67a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('dim_reducer', PCA()),\n",
    "    ('model', LogisticRegression())\n",
    "]\n",
    "\n",
    "model_pipe = Pipeline(estimators)\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'scaler': [StandardScaler(), None],\n",
    "        'dim_reducer':[PCA()],\n",
    "        'model': [KNeighborsClassifier()],\n",
    "        'model__n_neighbors': [7, 8, 9, 10, 11]\n",
    "        'dim_reducer__n_components': [0, 2, 3, 4, 5, 6]\n",
    "    }\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(model_pipe, param_grid, cv=5)\n",
    "knn_search = grid.fit(X_train2, y_train2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5850840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fittedsearch.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f81250",
   "metadata": {},
   "source": [
    "<a id='fit-val'></a>\n",
    "### Fit Optimized Model - Test on Validation Data\n",
    "##### Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931d8a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the logistic model\n",
    "log_base = LogisticRegression(random_state=9)\n",
    "log_base.fit(X_train2, y_train2)\n",
    "\n",
    "# Evaluate its classification accuracy (Just on the training set for now)\n",
    "print(f\"Train Set Accuracy: {log_base.score(X_train2, y_train2)}\")\n",
    "print(f\"Test Set Accuracy: {log_base.score(X_val, y_val)}\")\n",
    "\n",
    "# Instantiate\n",
    "dt_base = DecisionTreeClassifier(random_state=2)\n",
    "\n",
    "# Fit\n",
    "dt_base.fit(X_train2, y_train2)\n",
    "\n",
    "# Score\n",
    "print(f'Train Set Accuracy: {dt_base.score(X_train2, y_train2)}')\n",
    "print(f'Test Set Accuracy: {dt_base.score(X_val, y_val)}')\n",
    "\n",
    "# Instantiate the model & fit it to our data\n",
    "KNN_base = KNeighborsClassifier()\n",
    "KNN_base.fit(X_train2, y_train2)\n",
    "\n",
    "# Score the model on the test set\n",
    "print(\"Number of neighbors:\", KNN_base.n_neighbors)\n",
    "print(\"Train accuracy:\", KNN_base.score(X_train2, y_train2))\n",
    "print(\"Test accuracy:\", KNN_base.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28f7ca1",
   "metadata": {},
   "source": [
    "##### Fit Optimized Model to Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779d2c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the logistic model\n",
    "log_base = LogisticRegression(random_state=9)\n",
    "log_base.fit(X_train2, y_train2)\n",
    "\n",
    "# Evaluate its classification accuracy (Just on the training set for now)\n",
    "print(f\"Train Set Accuracy: {log_base.score(X_train2, y_train2)}\")\n",
    "print(f\"Test Set Accuracy: {log_base.score(X_val, y_val)}\")\n",
    "\n",
    "# Instantiate\n",
    "dt_base = DecisionTreeClassifier(random_state=2)\n",
    "\n",
    "# Fit\n",
    "dt_base.fit(X_train2, y_train2)\n",
    "\n",
    "# Score\n",
    "print(f'Train Set Accuracy: {dt_base.score(X_train2, y_train2)}')\n",
    "print(f'Test Set Accuracy: {dt_base.score(X_val, y_val)}')\n",
    "\n",
    "# Instantiate the model & fit it to our data\n",
    "KNN_base = KNeighborsClassifier()\n",
    "KNN_base.fit(X_train2, y_train2)\n",
    "\n",
    "# Score the model on the test set\n",
    "print(\"Number of neighbors:\", KNN_base.n_neighbors)\n",
    "print(\"Train accuracy:\", KNN_base.score(X_train2, y_train2))\n",
    "print(\"Test accuracy:\", KNN_base.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ae67ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e49779f",
   "metadata": {},
   "source": [
    "--------\n",
    "<a id='Step-4'></a>\n",
    "### 4. Model Evaluation\n",
    "--------\n",
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab599bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix\n",
    "\n",
    "# Get class predictions\n",
    "y_pred = credit_logit.predict(X_test)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d398bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label rows and columns\n",
    "cf_df = pd.DataFrame(\n",
    "    cf_matrix, \n",
    "    columns=[\"Predicted Non-fraudulent\", \"Predicted Fraudulent\"],\n",
    "    index=[\"True Non-fraudulent\", \"True Fraudulent\"]\n",
    ")\n",
    "\n",
    "display(cf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5af52c",
   "metadata": {},
   "source": [
    "<a id='auc-roc'></a>\n",
    "#### AUC-ROC Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6774e7dd",
   "metadata": {},
   "source": [
    "--------\n",
    "<a id='Step-5'></a>\n",
    "### 5. Class Balance\n",
    "--------\n",
    "From the *Part III: Logistic Regression* notebook, the balance of the data is imbalanced as most accidents are not fatal (approx. 81%). There are two lines of thinking:\n",
    "(1) Artificially balance the data through up sampling, down sammpling or Synthetic Minority Oversampling Technique (SMOTE)\n",
    "(2) Artificially balancing data improperly trains the model and introduces bias to the data resulting in poor model performance on new data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c833e50",
   "metadata": {},
   "source": [
    "#### Up Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7ad439",
   "metadata": {},
   "source": [
    "<a id='down-samp'></a>\n",
    "#### Down Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b164261",
   "metadata": {},
   "source": [
    "--------\n",
    "<a id='Step-6'></a>\n",
    "### 6. Results & Summary\n",
    "--------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
